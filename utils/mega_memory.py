# utils/mega_memory.py ‚Äî –ø—Ä–æ–∫–∞—á–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –†–∞
import os
import time
import zipfile
import hashlib
from datetime import datetime
from mega import Mega
import threading
from utils.notify import notify

# === –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ===
MEGA_EMAIL = os.getenv("MEGA_EMAIL") or "—Ç–≤–æ—è_–ø–æ—á—Ç–∞@mega.nz"
MEGA_PASSWORD = os.getenv("MEGA_PASSWORD") or "—Ç–≤–æ–π_–ø–∞—Ä–æ–ª—å"
LOCAL_MEMORY_DIR = "/app/memory"
LOCAL_LOGS_DIR = "/app/logs"
ARCHIVE_MEMORY = "ra_memory_backup.zip"
ARCHIVE_LOGS = "ra_logs_backup.zip"
CHECKSUM_FILE = "/app/memory/.last_sync_checksum"
SYNC_LOG = "/app/logs/mega_sync.log"
MAX_ARCHIVES = 5
SYNC_INTERVAL = 600  # —Å–µ–∫—É–Ω–¥ (10 –º–∏–Ω—É—Ç)

# === –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è ===
def ensure_dirs():
    for d in [LOCAL_MEMORY_DIR, LOCAL_LOGS_DIR]:
        os.makedirs(d, exist_ok=True)
    os.makedirs(os.path.dirname(SYNC_LOG), exist_ok=True)

def log(msg):
    ensure_dirs()
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    line = f"[{timestamp}] {msg}"
    print(line)
    try:
        with open(SYNC_LOG, "a", encoding="utf-8") as f:
            f.write(line + "\n")
    except:
        pass

# === –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Mega ===
def connect_to_mega():
    try:
        m = Mega().login(MEGA_EMAIL, MEGA_PASSWORD)
        log("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ Mega.nz")
        return m
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Mega: {e}")
        notify(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Mega: {e}")
        return None

# === –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è —Å—É–º–º–∞ –ø–∞–ø–∫–∏ ===
def get_directory_checksum(directory):
    hash_md5 = hashlib.md5()
    for root, _, files in os.walk(directory):
        for f in sorted(files):
            filepath = os.path.join(root, f)
            try:
                with open(filepath, "rb") as file:
                    for chunk in iter(lambda: file.read(4096), b""):
                        hash_md5.update(chunk)
            except:
                continue
    return hash_md5.hexdigest()

# === –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞ ===
def create_zip(directory, archive_name):
    ensure_dirs()
    archive_path = f"/app/{archive_name}"
    with zipfile.ZipFile(archive_path, "w", zipfile.ZIP_DEFLATED) as zipf:
        for root, _, files in os.walk(directory):
            for file in files:
                filepath = os.path.join(root, file)
                arcname = os.path.relpath(filepath, directory)
                zipf.write(filepath, arcname)
    return archive_path

# === –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –ª–æ–∫–∞–ª—å–Ω—ã—Ö –∞—Ä—Ö–∏–≤–æ–≤ ===
def cleanup_local_archives(base_name, keep=MAX_ARCHIVES):
    dir_path = "/app"
    archives = [f for f in os.listdir(dir_path) if f.startswith(base_name) and f.endswith(".zip")]
    if len(archives) <= keep:
        return
    archives.sort()
    for f in archives[:-keep]:
        try:
            os.remove(os.path.join(dir_path, f))
            log(f"üóëÔ∏è –£–¥–∞–ª—ë–Ω –ª–æ–∫–∞–ª—å–Ω—ã–π –∞—Ä—Ö–∏–≤: {f}")
        except:
            log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–π –∞—Ä—Ö–∏–≤: {f}")

# === –ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ö–∏–≤–∞ –≤ Mega ===
def upload_to_mega(archive_name, archive_path):
    m = connect_to_mega()
    if not m:
        log(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É {archive_name} ‚Äî Mega –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")
        notify(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑–∫–∏ {archive_name} ‚Äî Mega –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        return
    try:
        m.upload(archive_path)
        log(f"üíæ –ê—Ä—Ö–∏–≤ {archive_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ Mega.")
        notify(f"üíæ –ê—Ä—Ö–∏–≤ {archive_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ Mega")
        cleanup_local_archives(os.path.splitext(archive_name)[0])
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {archive_name}: {e}")
        notify(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {archive_name}: {e}")

# === –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞ –∏–∑ Mega ===
def restore_from_mega():
    ensure_dirs()
    m = connect_to_mega()
    if not m:
        return
    try:
        files = m.get_files()
        archive_id = next((fid for fid, data in files.items() if data['a']['n'] == ARCHIVE_MEMORY), None)
        if not archive_id:
            log("‚ö†Ô∏è –ê—Ä—Ö–∏–≤ –ø–∞–º—è—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ Mega.")
            notify("‚ö†Ô∏è –ê—Ä—Ö–∏–≤ –ø–∞–º—è—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ Mega")
            return
        archive_path = f"/app/{ARCHIVE_MEMORY}"
        m.download(files[archive_id], dest_filename=archive_path)
        with zipfile.ZipFile(archive_path, "r") as zipf:
            zipf.extractall(LOCAL_MEMORY_DIR)
        log("üß† –ü–∞–º—è—Ç—å –†–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑ Mega.")
        notify("üß† –ü–∞–º—è—Ç—å –†–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑ Mega")
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ –ø–∞–º—è—Ç–∏: {e}")
        notify(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ –ø–∞–º—è—Ç–∏: {e}")

# === –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ ===
def backup_to_mega():
    ensure_dirs()
    new_checksum = get_directory_checksum(LOCAL_MEMORY_DIR)
    old_checksum = None
    if os.path.exists(CHECKSUM_FILE):
        with open(CHECKSUM_FILE, "r") as f:
            old_checksum = f.read().strip()
    if new_checksum == old_checksum:
        log("üü¢ –ü–∞–º—è—Ç—å –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –≤ Mega.")
        return
    archive_path = create_zip(LOCAL_MEMORY_DIR, ARCHIVE_MEMORY)
    upload_to_mega(ARCHIVE_MEMORY, archive_path)
    with open(CHECKSUM_FILE, "w") as f:
        f.write(new_checksum)

# === –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–æ–≥–æ–≤ ===
def backup_logs_to_mega():
    ensure_dirs()
    archive_path = create_zip(LOCAL_LOGS_DIR, ARCHIVE_LOGS)
    upload_to_mega(ARCHIVE_LOGS, archive_path)

# === –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –ª–æ–≥–æ–≤ (>7 –¥–Ω–µ–π) ===
def archive_old_logs(days=7):
    cutoff = time.time() - days*24*3600
    for f in os.listdir(LOCAL_LOGS_DIR):
        path = os.path.join(LOCAL_LOGS_DIR, f)
        if os.path.isfile(path) and os.path.getmtime(path) < cutoff:
            archive_name = f"old_logs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
            archive_path = os.path.join("/app", archive_name)
            with zipfile.ZipFile(archive_path, "w", zipfile.ZIP_DEFLATED) as zipf:
                zipf.write(path, arcname=f)
            os.remove(path)
            upload_to_mega(archive_name, archive_path)

# === –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ –∏ –ª–æ–≥–æ–≤ ===
def start_auto_sync():
    ensure_dirs()
    def sync_loop():
        while True:
            try:
                backup_to_mega()
                backup_logs_to_mega()
                archive_old_logs()
                log("üîÅ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è Mega –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ.")
                notify("üîÅ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ –∏ –ª–æ–≥–æ–≤ —Å Mega –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            except Exception as e:
                log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–≤—Ç–æ-—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")
                notify(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–≤—Ç–æ-—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")
            time.sleep(SYNC_INTERVAL)
    threading.Thread(target=sync_loop, daemon=True).start()
    log("üåê –ê–≤—Ç–æ-—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è Mega –∑–∞–ø—É—â–µ–Ω–∞.")
