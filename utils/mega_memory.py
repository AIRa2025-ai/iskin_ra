# utils/mega_memory.py
import os
import time
import zipfile
import hashlib
from datetime import datetime
from mega_wrapper import upload_file_sync
import threading
import signal
from collections import deque
from utils.notify import notify
from mega import Mega  # —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π

# === –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ===
MEGA_EMAIL = os.getenv("MEGA_EMAIL") or "osvobozhdenie.ra@gmail.com"
MEGA_PASSWORD = os.getenv("MEGA_PASSWORD") or "Dbhec19771984"
LOCAL_MEMORY_DIR = "memory"
LOCAL_LOGS_DIR = "logs"
ARCHIVE_MEMORY = "ra_memory_backup.zip"
ARCHIVE_LOGS = "ra_logs_backup.zip"
CHECKSUM_FILE = "/app/memory/.last_sync_checksum"
SYNC_LOG = "/app/logs/mega_sync.log"
MAX_ARCHIVES = 5
SYNC_INTERVAL = 600  # —Å–µ–∫—É–Ω–¥ (10 –º–∏–Ω—É—Ç)
MAX_RETRIES = 3
RETRY_DELAY = 10

stop_flag = False

# === –°–∏–≥–Ω–∞–ª—ã ===
def signal_handler(signum, frame):
    global stop_flag
    log(f"‚úã –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª {signum}, –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—é...")
    stop_flag = True

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# === –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ===
def ensure_dirs():
    for d in [LOCAL_MEMORY_DIR, LOCAL_LOGS_DIR]:
        os.makedirs(d, exist_ok=True)
    os.makedirs(os.path.dirname(SYNC_LOG), exist_ok=True)

def log(msg):
    ensure_dirs()
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    line = f"[{timestamp}] {msg}"
    print(line)
    try:
        with open(SYNC_LOG, "a", encoding="utf-8") as f:
            f.write(line + "\n")
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –ª–æ–≥: {e}")

def get_directory_checksum(directory):
    hash_md5 = hashlib.md5()
    for root, _, files in os.walk(directory):
        for f in sorted(files):
            filepath = os.path.join(root, f)
            try:
                with open(filepath, "rb") as file:
                    for chunk in iter(lambda: file.read(4096), b""):
                        hash_md5.update(chunk)
            except Exception as e:
                log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ {filepath}: {e}")
    return hash_md5.hexdigest()

def create_zip(directory, archive_name):
    ensure_dirs()
    archive_path = f"/app/{archive_name}"
    try:
        with zipfile.ZipFile(archive_path, "w", zipfile.ZIP_DEFLATED) as zipf:
            for root, _, files in os.walk(directory):
                for file in files:
                    filepath = os.path.join(root, file)
                    arcname = os.path.relpath(filepath, directory)
                    zipf.write(filepath, arcname)
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∞—Ä—Ö–∏–≤–∞ {archive_name}: {e}")
    return archive_path

def cleanup_local_archives(base_name, keep=MAX_ARCHIVES):
    dir_path = "/app"
    archives = [f for f in os.listdir(dir_path) if f.startswith(base_name) and f.endswith(".zip")]
    if len(archives) <= keep:
        return
    archives.sort()
    for f in archives[:-keep]:
        try:
            os.remove(os.path.join(dir_path, f))
            log(f"üóëÔ∏è –£–¥–∞–ª—ë–Ω —Å—Ç–∞—Ä—ã–π –∞—Ä—Ö–∏–≤: {f}")
        except Exception as e:
            log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –∞—Ä—Ö–∏–≤ {f}: {e}")

# === –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Mega ===
def connect_to_mega():
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            m = Mega()
            m.login(MEGA_EMAIL, MEGA_PASSWORD)
            log("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ Mega.nz")
            return m
        except Exception as e:
            log(f"‚ùå –ü–æ–ø—ã—Ç–∫–∞ {attempt} ‚Äî –æ—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Mega: {e}")
            notify(f"‚ùå –ü–æ–ø—ã—Ç–∫–∞ {attempt} ‚Äî –æ—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Mega: {e}")
            time.sleep(RETRY_DELAY)
    log("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Mega –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—ã—Ç–æ–∫")
    return None

def upload_to_mega(archive_name, archive_path):
    if stop_flag:
        log(f"‚úã –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É {archive_name} ‚Äî —Å—Ç–æ–ø –∞–∫—Ç–∏–≤–µ–Ω")
        return
    m = connect_to_mega()
    if not m:
        return
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            m.upload(archive_path)
            log(f"üíæ –ê—Ä—Ö–∏–≤ {archive_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω")
            notify(f"üíæ –ê—Ä—Ö–∏–≤ {archive_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω")
            cleanup_local_archives(os.path.splitext(archive_name)[0])
            return
        except Exception as e:
            log(f"‚ùå –ü–æ–ø—ã—Ç–∫–∞ {attempt} ‚Äî –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {archive_name}: {e}")
            time.sleep(RETRY_DELAY)
    log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {archive_name} –ø–æ—Å–ª–µ {MAX_RETRIES} –ø–æ–ø—ã—Ç–æ–∫")

def restore_from_mega():
    ensure_dirs()
    if stop_flag:
        log("‚úã –ü—Ä–æ–ø—É—Å–∫ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è ‚Äî —Å—Ç–æ–ø –∞–∫—Ç–∏–≤–µ–Ω")
        return

    for attempt in range(1, MAX_RETRIES + 1):
        try:
            m = Mega()
            m.login(MEGA_EMAIL, MEGA_PASSWORD)
            files = m.get_files()
            archive_id = next(
                (fid for fid, data in files.items() if data.get('a', {}).get('n') == ARCHIVE_MEMORY),
                None
            )
            if not archive_id:
                log(f"‚ö†Ô∏è –ê—Ä—Ö–∏–≤ –ø–∞–º—è—Ç–∏ {ARCHIVE_MEMORY} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ Mega")
                notify(f"‚ö†Ô∏è –ê—Ä—Ö–∏–≤ –ø–∞–º—è—Ç–∏ {ARCHIVE_MEMORY} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ Mega")
                return

            archive_path = f"/app/{ARCHIVE_MEMORY}"
            temp_path = f"/app/tmp_{ARCHIVE_MEMORY}"
            m.download(files[archive_id], dest_filename=temp_path)

            # –≤—ã—á–∏—Å–ª—è–µ–º md5 —Å–∫–∞—á–∞–Ω–Ω–æ–≥–æ –∞—Ä—Ö–∏–≤–∞
            hash_md5 = hashlib.md5()
            with open(temp_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            new_checksum = hash_md5.hexdigest()

            old_checksum = None
            if os.path.exists(CHECKSUM_FILE):
                try:
                    with open(CHECKSUM_FILE, "r") as f:
                        old_checksum = f.read().strip()
                except Exception as e:
                    log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—É—é –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é —Å—É–º–º—É: {e}")

            if new_checksum == old_checksum:
                log("‚úÖ –ü–∞–º—è—Ç—å –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å, –ø–µ—Ä–µ–∑–∞–ø–∏—Å—å –Ω–µ –Ω—É–∂–Ω–∞")
                os.remove(temp_path)
                return

            os.replace(temp_path, archive_path)
            with zipfile.ZipFile(archive_path, "r") as zipf:
                zipf.extractall(LOCAL_MEMORY_DIR)

            try:
                with open(CHECKSUM_FILE, "w") as f:
                    f.write(new_checksum)
            except Exception as e:
                log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é —Å—É–º–º—É –ø–æ—Å–ª–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: {e}")

            log("üß† –ü–∞–º—è—Ç—å –†–∞ —É—Å–ø–µ—à–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑ Mega")
            notify("üß† –ü–∞–º—è—Ç—å –†–∞ —É—Å–ø–µ—à–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∞")
            return

        except Exception as e:
            log(f"‚ùå –ü–æ–ø—ã—Ç–∫–∞ {attempt} ‚Äî –æ—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏: {e}")
            time.sleep(RETRY_DELAY)

    log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–∞–º—è—Ç—å –ø–æ—Å–ª–µ {MAX_RETRIES} –ø–æ–ø—ã—Ç–æ–∫")

def backup_memory_and_logs():
    new_checksum = get_directory_checksum(LOCAL_MEMORY_DIR)
    old_checksum = None
    if os.path.exists(CHECKSUM_FILE):
        try:
            with open(CHECKSUM_FILE, "r") as f:
                old_checksum = f.read().strip()
        except Exception as e:
            log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é —Å—É–º–º—É: {e}")

    if new_checksum != old_checksum:
        archive_path = create_zip(LOCAL_MEMORY_DIR, ARCHIVE_MEMORY)
        upload_to_mega(ARCHIVE_MEMORY, archive_path)
        try:
            with open(CHECKSUM_FILE, "w") as f:
                f.write(new_checksum)
        except Exception as e:
            log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é —Å—É–º–º—É: {e}")

    archive_path_logs = create_zip(LOCAL_LOGS_DIR, ARCHIVE_LOGS)
    upload_to_mega(ARCHIVE_LOGS, archive_path_logs)

def archive_old_logs(days=7):
    cutoff = time.time() - days*24*3600
    for f in os.listdir(LOCAL_LOGS_DIR):
        path = os.path.join(LOCAL_LOGS_DIR, f)
        if os.path.isfile(path) and os.path.getmtime(path) < cutoff:
            archive_name = f"old_logs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
            archive_path = os.path.join("/app", archive_name)
            try:
                with zipfile.ZipFile(archive_path, "w", zipfile.ZIP_DEFLATED) as zipf:
                    zipf.write(path, arcname=f)
                os.remove(path)
                upload_to_mega(archive_name, archive_path)
            except Exception as e:
                log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç–∞—Ä–æ–≥–æ –ª–æ–≥–∞ {f}: {e}")

def start_auto_sync():
    ensure_dirs()
    def sync_loop():
        restart_times = deque()
        while not stop_flag:
            now = time.time()
            while restart_times and now - restart_times[0] > 60:
                restart_times.popleft()
            num_recent_restarts = len(restart_times)
            sleep_time = min(5 * (2 ** num_recent_restarts), 120)

            if num_recent_restarts >= MAX_ARCHIVES:
                log(f"‚ö†Ô∏è –ú–Ω–æ–≥–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–≤ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏, –ø–∞—É–∑–∞ {sleep_time}s")
                time.sleep(sleep_time)
                restart_times.clear()
                continue

            try:
                restart_times.append(time.time())
                backup_memory_and_logs()
                archive_old_logs()
                log("üîÅ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è Mega –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                notify("üîÅ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ –∏ –ª–æ–≥–æ–≤ —Å Mega –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            except Exception as e:
                log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–≤—Ç–æ-—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")
                notify(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–≤—Ç–æ-—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")

            for _ in range(SYNC_INTERVAL):
                if stop_flag:
                    break
                time.sleep(1)

    threading.Thread(target=sync_loop, daemon=True).start()
    log("üåê –ê–≤—Ç–æ-—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è Mega –∑–∞–ø—É—â–µ–Ω–∞")
