# modules/ra_downloader_async.py
import os
import zipfile
import asyncio
import logging
from pathlib import Path
from typing import Set, Dict, Optional
from datetime import datetime
import aiohttp
import json
import errno

# –ü–æ–ø—ã—Ç–∫–∞ –≤–∑—è—Ç—å ARCHIVE_URL –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ—Å—Ç:
# 1) RA_ARCHIVE_URL (–ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ)
# 2) ARCHIVE_URL (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
# 3) modules.ra_config.ARCHIVE_URL (–µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
def _resolve_archive_url() -> str:
    env_url = os.getenv("RA_ARCHIVE_URL") or os.getenv("ARCHIVE_URL")
    if env_url:
        return env_url
    try:
        # –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥, –µ—Å–ª–∏ –µ—Å—Ç—å
        import modules.ra_config as rc  # type: ignore
        return getattr(rc, "ARCHIVE_URL", "") or ""
    except Exception:
        return ""

ARCHIVE_URL = _resolve_archive_url()
DATA_DIR = Path(os.getenv("RA_DATA_DIR", "data"))
LOCAL_ZIP = DATA_DIR / "RaSvet.zip"
EXTRACT_DIR = DATA_DIR / "RaSvet"
EXTRACT_META = DATA_DIR / "RaSvet.extract.meta"
META_JSON = DATA_DIR / "RaSvet.meta.json"
LOCK_FILE = DATA_DIR / ".rasvet_downloader.lock"

DATA_DIR.mkdir(parents=True, exist_ok=True)
EXTRACT_DIR.mkdir(parents=True, exist_ok=True)

logger = logging.getLogger("RaSvetDownloaderAsync")
logger.setLevel(logging.INFO)
handler = logging.StreamHandler()
formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
handler.setFormatter(formatter)
if not logger.handlers:
    logger.addHandler(handler)


class KnowledgeBase:
    def __init__(self):
        self.documents: Dict[str, Dict] = {}

    async def load_from_folder(self, folder: Path):
        self.documents = {}
        try:
            for file in Path(folder).rglob("*"):
                if file.is_file() and file.suffix.lower() in [".txt", ".md", ".json"]:
                    try:
                        self.documents[file.name] = {
                            "content": file.read_text(encoding="utf-8"),
                            "mtime": datetime.fromtimestamp(file.stat().st_mtime)
                        }
                    except Exception as e:
                        logger.warning(f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å {file}: {e}")
            logger.info(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–Ω–∞–Ω–∏–π: {len(self.documents)} —Ñ–∞–π–ª–æ–≤")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑ –ø–∞–ø–∫–∏ {folder}: {e}")

    async def ask(self, question: str, user_id=None) -> Optional[str]:
        if not question:
            return None
        answers = []
        sorted_docs = sorted(self.documents.items(), key=lambda x: x[1].get("mtime", datetime.min), reverse=True)
        for fname, meta in sorted_docs:
            try:
                if question.lower() in meta["content"].lower():
                    snippet = meta["content"][:500].replace("\n", " ")
                    answers.append(f"[{fname}] {snippet}...")
            except Exception:
                continue
        return "\n\n".join(answers[:5]) if answers else None


def _is_valid_zip(path: Path) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º zip: –æ—Ç–∫—Ä—ã–≤–∞–µ–º –∏ –¥–µ–ª–∞–µ–º testzip(). –í–æ–∑–≤—Ä–∞—â–∞–µ–º True, –µ—Å–ª–∏ –∞—Ä—Ö–∏–≤ —Ü–µ–ª—ã–π."""
    try:
        with zipfile.ZipFile(path, 'r') as z:
            bad = z.testzip()  # –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–º—è –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–æ–±–ª–µ–º–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∏–ª–∏ None
            if bad:
                logger.warning(f"‚ùå ZIP test failed, bad member: {bad}")
                return False
            return True
    except zipfile.BadZipFile:
        logger.warning("‚ùå BadZipFile –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∞—Ä—Ö–∏–≤–∞")
        return False
    except Exception as e:
        logger.warning(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ zip: {e}")
        return False


def _acquire_lock() -> bool:
    """
    –ü—Ä–æ—Å—Ç–∞—è —Ñ–∞–π–ª–æ–≤–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞: —Å–æ–∑–¥–∞—ë–º LOCK_FILE —Å O_EXCL.
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º True –µ—Å–ª–∏ –∑–∞—Ö–≤–∞—Ç–∏–ª–∏, False –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å.
    """
    try:
        fd = os.open(str(LOCK_FILE), os.O_CREAT | os.O_EXCL | os.O_WRONLY)
        os.close(fd)
        return True
    except OSError as e:
        if e.errno == errno.EEXIST:
            return False
        raise


def _release_lock():
    try:
        if LOCK_FILE.exists():
            LOCK_FILE.unlink()
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å lock-—Ñ–∞–π–ª: {e}")


class RaSvetDownloaderAsync:
    def __init__(self):
        self.knowledge = KnowledgeBase()
        self.extracted_files: Set[str] = set()
        self.meta_data: Dict[str, Dict] = {}
        # —á–∏—Ç–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏
        if EXTRACT_META.exists():
            try:
                self.extracted_files = set(line.strip() for line in EXTRACT_META.read_text(encoding="utf-8").splitlines() if line.strip())
            except Exception:
                self.extracted_files = set()
        if META_JSON.exists():
            try:
                self.meta_data = json.loads(META_JSON.read_text(encoding="utf-8"))
            except Exception:
                self.meta_data = {}

    async def download_async(self):
        """–ì–ª–∞–≤–Ω—ã–π –≤—Ö–æ–¥ ‚Äî —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è) –∏ –±–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞."""
        # –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞, —á—Ç–æ–±—ã –¥–≤–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ –Ω–µ –¥–µ–ª–∞–ª–∏ –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
        got_lock = False
        try:
            got_lock = _acquire_lock()
            if not got_lock:
                logger.info("üîí –î—Ä—É–≥–æ–π –ø—Ä–æ—Ü–µ—Å—Å —É–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ/—Ä–∞—Å–ø–∞–∫–æ–≤–∫—É ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                # –¥–∞–∂–µ –µ—Å–ª–∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ, –ø–æ–ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —É–∂–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è
                await self.knowledge.load_from_folder(EXTRACT_DIR)
                return

            await self._download_archive_if_needed()
            await self._safe_extract_incremental()
            await self.knowledge.load_from_folder(EXTRACT_DIR)
        finally:
            if got_lock:
                _release_lock()

    async def _download_archive_if_needed(self):
        archive_url = ARCHIVE_URL or ""
        if not archive_url:
            logger.warning("ARCHIVE_URL not configured ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ")
            return

        # –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å remote size, –Ω–æ –µ—Å–ª–∏ HEAD –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç Size ‚Äî graceful fallback
        try:
            timeout = aiohttp.ClientTimeout(total=120)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                remote_size = 0
                try:
                    async with session.head(archive_url) as resp:
                        resp.raise_for_status()
                        remote_size = int(resp.headers.get("Content-Length") or 0)
                except Exception:
                    remote_size = 0

                local_size = LOCAL_ZIP.stat().st_size if LOCAL_ZIP.exists() else 0

                # –ï—Å–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã–π –µ—Å—Ç—å ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å zip; –µ—Å–ª–∏ –ø–æ–≤—Ä–µ–∂–¥—ë–Ω ‚Äî –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–∫–∞—á–∞—Ç—å.
                local_valid = LOCAL_ZIP.exists() and _is_valid_zip(LOCAL_ZIP)

                need_download = False
                if not LOCAL_ZIP.exists():
                    need_download = True
                elif remote_size and local_size != remote_size:
                    # —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã ‚Äî –ø–µ—Ä–µ–∫–∞—á–∞—Ç—å
                    need_download = True
                elif not local_valid:
                    # –ª–æ–∫–∞–ª—å–Ω—ã–π –µ—Å—Ç—å, –Ω–æ –±–∏—Ç—ã–π ‚Äî –ø–µ—Ä–µ–∫–∞—á–∞—Ç—å
                    need_download = True

                if not need_download:
                    logger.info("‚ÑπÔ∏è –ê—Ä—Ö–∏–≤ –∞–∫—Ç—É–∞–ª–µ–Ω –∏ –≤–∞–ª–∏–¥–Ω—ã–π, —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ")
                    return

                # –¥–µ–ª–∞–µ–º –¥–æ 2 –ø–æ–ø—ã—Ç–æ–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–µ—Å–ª–∏ —Å–∫–∞—á–∞–ª–∏, –Ω–æ –∞—Ä—Ö–∏–≤ –±–∏—Ç—ã–π, –ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑)
                attempts = 2
                for attempt in range(1, attempts + 1):
                    try:
                        logger.info(f"‚¨áÔ∏è –ù–∞—á–∏–Ω–∞—é —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞ RaSvet (–ø–æ–ø—ã—Ç–∫–∞ {attempt}/{attempts})")
                        async with session.get(archive_url) as resp:
                            resp.raise_for_status()
                            with open(LOCAL_ZIP, "wb") as f:
                                async for chunk in resp.content.iter_chunked(32 * 1024):
                                    if chunk:
                                        f.write(chunk)
                                    await asyncio.sleep(0)
                        logger.info("‚úÖ –ê—Ä—Ö–∏–≤ —Å–∫–∞—á–∞–Ω")
                        # –ø—Ä–æ–≤–µ—Ä—è–µ–º
                        if _is_valid_zip(LOCAL_ZIP):
                            logger.info("‚úÖ –°–∫–∞—á–∞–Ω–Ω—ã–π –∞—Ä—Ö–∏–≤ –≤–∞–ª–∏–¥–µ–Ω")
                            break
                        else:
                            logger.warning("‚ö†Ô∏è –°–∫–∞—á–∞–Ω–Ω—ã–π –∞—Ä—Ö–∏–≤ –æ–∫–∞–∑–∞–ª—Å—è –ø–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω—ã–º")
                            if attempt == attempts:
                                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∞—Ä—Ö–∏–≤ –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—ã—Ç–æ–∫")
                        # –µ—Å–ª–∏ —Ü–∏–∫–ª –Ω–µ break ‚Äî —Å–ª–µ–¥—É—é—â–∞—è –ø–æ–ø—ã—Ç–∫–∞
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –∞—Ä—Ö–∏–≤–∞: {e}")
                        if attempt == attempts:
                            logger.error("‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–µ—Ç–µ–≤–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏: {e}")

    async def _safe_extract_incremental(self):
        EXTRACT_DIR.mkdir(parents=True, exist_ok=True)
        new_files = set()

        if not LOCAL_ZIP.exists():
            logger.warning("‚ö† –ù–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∞—Ä—Ö–∏–≤–∞ –¥–ª—è —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏")
            return

        # –µ—Å–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã–π zip –ø–æ–≤—Ä–µ–∂–¥—ë–Ω ‚Äî –Ω–µ —Ä–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º
        if not _is_valid_zip(LOCAL_ZIP):
            logger.error("‚ùå –ê—Ä—Ö–∏–≤ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω, —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞")
            return

        try:
            with zipfile.ZipFile(LOCAL_ZIP, 'r') as zip_ref:
                for member in zip_ref.infolist():
                    try:
                        # –∏–∑–±–µ–≥–∞–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö traversal-–∞—Ç–∞–∫ ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—É—Ç–∏
                        member_name = member.filename
                        # –ø—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: –µ—Å–ª–∏ —Ä–∞–∑–º–µ—Ä –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è –∏ —É–∂–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω–æ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        meta = self.meta_data.get(member_name, {})
                        size_changed = meta.get("size") != member.file_size
                        if member_name in self.extracted_files and not size_changed:
                            continue
                        # –∏–∑–≤–ª–µ–∫–∞–µ–º
                        zip_ref.extract(member, EXTRACT_DIR)
                        logger.info(f"üìÇ –†–∞—Å–ø–∞–∫–æ–≤–∞–Ω: {member_name}")
                        new_files.add(member_name)
                        self.meta_data[member_name] = {"size": member.file_size, "mtime": datetime.now().isoformat()}
                        # –¥–∞—ë–º —à–∞–Ωc –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫—É (–Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º)
                        await asyncio.sleep(0)
                    except zipfile.BadZipFile:
                        logger.error("‚ùå –ê—Ä—Ö–∏–≤ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ member")
                        continue
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–µ {member.filename}: {e}")
        except zipfile.BadZipFile:
            logger.error("‚ùå –ê—Ä—Ö–∏–≤ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω, —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞")
            return
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–µ –∞—Ä—Ö–∏–≤–∞: {e}")
            return

        if new_files:
            self.extracted_files.update(new_files)
            try:
                EXTRACT_META.write_text("\n".join(sorted(self.extracted_files)), encoding="utf-8")
                META_JSON.write_text(json.dumps(self.meta_data, ensure_ascii=False, indent=2), encoding="utf-8")
                logger.info(f"üåû –û–±–Ω–æ–≤–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(new_files)}")
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏: {e}")

        # —É–¥–∞–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –∞—Ä—Ö–∏–≤ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ (–∏ ZIP –≤–∞–ª–∏–¥–µ–Ω)
        try:
            if LOCAL_ZIP.exists():
                try:
                    # –µ—â—ë —Ä–∞–∑ –ø—Ä–æ–≤–µ—Ä–∏–º —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º
                    if _is_valid_zip(LOCAL_ZIP):
                        LOCAL_ZIP.unlink()
                        logger.info("üßπ –õ–æ–∫–∞–ª—å–Ω—ã–π –∞—Ä—Ö–∏–≤ —É–¥–∞–ª—ë–Ω –ø–æ—Å–ª–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏")
                    else:
                        logger.warning("‚ö†Ô∏è –õ–æ–∫–∞–ª—å–Ω—ã–π –∞—Ä—Ö–∏–≤ –Ω–µ —É–¥–∞–ª—ë–Ω ‚Äî –æ–Ω –≤—ã–≥–ª—è–¥–∏—Ç –ø–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω—ã–º")
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–π –∞—Ä—Ö–∏–≤: {e}")
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ —É–¥–∞–ª–µ–Ω–∏—è –∞—Ä—Ö–∏–≤–∞: {e}")
