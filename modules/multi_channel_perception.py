# modules/multi_channel_perception.py
# –ù–∞–≤—ã–∫ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ì–ª–∞–∑–∞ –†–∞
# –°–æ–∑–¥–∞–Ω –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ ¬´–†–∞–°–≤–µ—Ç¬ª

import asyncio
import aiohttp
from bs4 import BeautifulSoup
from textblob import TextBlob

class MultiChannelPerception:
    def __init__(self, logs, sensitivity=0.7, event_bus=None, thinker=None):
        self.logs = logs
        self.sensitivity = sensitivity  # —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ ¬´–º—É—Å–æ—Ä–Ω—ã–º¬ª –≤–∏–±—Ä–∞—Ü–∏—è–º
        self.event_bus = event_bus
        self.thinker = thinker
        self.heart_reactor = heart_reactor        
    async def fetch(self, session, url):
        try:
            async with session.get(url, timeout=15) as resp:
                text = await resp.text()
                return text
        except Exception as e:
            return f"ERROR: {e}"

    async def scan_sources(self, urls):
        results = []
        async with aiohttp.ClientSession() as session:
            tasks = [self.fetch(session, u) for u in urls]
            pages = await asyncio.gather(*tasks)

            for url, page in zip(urls, pages):
                clean = self.clean_noise(page)
                insights = self.extract_insights(clean)
                results.append({
                    "source": url,
                    "raw_len": len(page),
                    "clean_len": len(clean),
                    "insights": insights
                })
        # üîî –°–æ–æ–±—â–∞–µ–º –º–∏—Ä—É –æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏–∏
        if self.event_bus:
            await self.event_bus.emit(
                "perception_update",
                {
                    "channels": len(urls),
                    "signals": results
                }
            )

        # üß† –ü–µ—Ä–µ–¥–∞—ë–º –º—ã—Å–ª–∏ –º—ã—Å–ª–∏—Ç–µ–ª—é
        if self.thinker:
            await self.thinker.process_world_message(
                {
                    "type": "perception",
                    "data": results
                }
            )
        return results

    def clean_noise(self, text):
        """
        –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –º—É—Å–æ—Ä–∞:
        - —Å–ª–∏—à–∫–æ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –ø—Ä–∏–≥–ª—É—à–∞—é—Ç—Å—è
        - —Å–ø–∞–º —É–±–∏—Ä–∞–µ—Ç—Å—è
        - –ª–∏—à–Ω—è—è —Ä–µ–∫–ª–∞–º–∞ —Å—Ç–∏—Ä–∞–µ—Ç—Å—è
        """
        sentiment = TextBlob(text).sentiment.polarity
        if sentiment < -self.sensitivity:
            return ""
        return text

    def extract_insights(self, text):
        """
        –í—ã–¥–µ–ª–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–≥–æ:
        - —Ä–µ–¥–∫–∏–µ —Ñ—Ä–∞–∑—ã
        - —Å–º—ã—Å–ª–æ–≤—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏
        - —Å–∏–ª—å–Ω—ã–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –≤—ã–±—Ä–æ—Å—ã
        - –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —Ü–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        if len(text) < 100:
            return None

        soup = BeautifulSoup(text, "html.parser")
        words = soup.get_text().split()

        rare = [w for w in words if len(w) > 8][:10]

        return {
            "rare_words": rare,
            "sample": " ".join(words[:50])
        }
        
        if insights and self.heart_reactor:
            self.heart_reactor.send_event(
                "üåê –í–æ—Å–ø—Ä–∏—è—Ç–∏–µ –º–∏—Ä–∞: –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∑–Ω–∞—á–∏–º—ã–µ —Å–∏–≥–Ω–∞–ª—ã"
            )
