# core/gpt_handler.py

import asyncio
import json
import os
import logging
from core.model_router import ModelRouter

log = logging.getLogger("GPTHandler")

class GPTHandler:
    CACHE_FILE = "data/gpt_cache.json"

    def __init__(self, openrouter_client):
        self.client = openrouter_client
        self.router = ModelRouter()
        self.cache = self._load_cache()

    # -------------------
    # –ö–≠–®
    # -------------------
    def _load_cache(self):
        if os.path.exists(self.CACHE_FILE):
            try:
                with open(self.CACHE_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except:
                pass
        return {}

    def _save_cache(self):
        os.makedirs(os.path.dirname(self.CACHE_FILE), exist_ok=True)
        with open(self.CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump(self.cache, f, ensure_ascii=False, indent=2)

    # -------------------
    # –ì–õ–ê–í–ù–û–ï: –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
    # -------------------
    async def safe_ask(self, user_id, messages):
        key = json.dumps(messages, ensure_ascii=False)

        if user_id in self.cache and key in self.cache[user_id]:
            return self.cache[user_id][key]

        last_error = None

        for _ in range(len(self.router.MODELS)):
            model = self.router.get_model()
            try:
                log.info(f"üß† GPT –ø—Ä–æ–±—É–µ—Ç –º–æ–¥–µ–ª—å: {model}")
                response = await self.client.ask(model, messages)
                
                self.cache.setdefault(user_id, {})[key] = response
                self._save_cache()
                return response

            except Exception as e:
                log.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {model} —É–ø–∞–ª–∞: {e}")
                self.router.mark_failed(model)
                last_error = e

        raise Exception(f"–í—Å–µ –º–æ–¥–µ–ª–∏ –æ—Ç–∫–∞–∑–∞–ª–∏: {last_error}")

    # -------------------
    # –§–æ–Ω–æ–≤—ã–π –º–æ–Ω–∏—Ç–æ—Ä
    # -------------------
    async def background_model_monitor(self):
        while True:
            try:
                self.router.refresh()
            except Exception as e:
                log.warning(f"[GPTHandler] –û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –º–æ–¥–µ–ª–µ–π: {e}")
            await asyncio.sleep(300)
